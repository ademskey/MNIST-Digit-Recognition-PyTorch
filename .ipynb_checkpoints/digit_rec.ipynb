{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # Import neural networks (nn)\n",
    "import torch.nn.functional as F  # Import nn functionality\n",
    "import torch.optim as optim  # Import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torchvision to download training data\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True, # Use ToTensor to define the transformation method\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pytorch loaders\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data, batch_size = 100, shuffle=True, num_workers=1),\n",
    "    'test': DataLoader(test_data, batch_size = 100, shuffle=True, num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x220f0b2ad20>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x220ef03f4d0>}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network architecture\n",
    "class CNN(nn.Module):  # define nn as convolutional neural network, inherit from nn.Module\n",
    "    # Define initialization\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # Calls constructor of parent class\n",
    "\n",
    "        '''\n",
    "        Defines convulational layers for feature extraction\n",
    "        '''\n",
    "        # Create NN layers\n",
    "        # defines first layer with 1 input channel, 10 output chanels, and kernal size of 5x5    \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "\n",
    "        # Defines second layer with 10 input channels from first layer and 20 output channels\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "\n",
    "        # Defines dropout layer which regularizes by randomly zeroing elements to prevent overfitting\n",
    "        self.conv2_drop = nn.Dropout2d() # regularization layer\n",
    "\n",
    "        # Deffines first fullyconnected/dense layer \n",
    "        self.fc1 = nn.Linear(320, 50) # 320 calculated from output of conv2\n",
    "\n",
    "        # defines second dense layer with 50 inpput and 10 output corresponding to digits 0-9\n",
    "        self.fc2 = nn.Linear(50, 10) # 10 outputs for digit class\n",
    "\n",
    "    def forward(self, x): # defines activation function\n",
    "        '''\n",
    "        applies rectified linear unit function (relu) as the activation function (introduce non-linearity\n",
    "        to learn more complex patterns and relationships in data) to max pooling (operation that caluclates \n",
    "        maximum value for patches of feature map) to reduce the dimensionality. \n",
    "        '''\n",
    "        # torch.nn.functional.relu(input, inplace=False) â†’ Tensor[SOURCE]\n",
    "        # applies the recefied lienar unit function element-wise to max pooling of input planes\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "\n",
    "        # applies second convolution to result and applies dropout, max pooling, and ReLU\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "\n",
    "        # shapes x into 1-dimensional tensor with 320 inputs needed for deep layers\n",
    "        x = x.view(-1, 320) # 20 * 4 * 4 = 320 Should flatten x to have size 320\n",
    "\n",
    "        # applies relu to first output layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # applies droput regularization to first output\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # computes the scores for each of the 10 classes using last layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # returns softmax (rescales so that elements line in range)\n",
    "        # normalizes logits into probabilities for confidence. Takes highest as answer\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure device to detect if NVIDIA cuda enabled gpu is avaliable\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assign device to NN\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Configure optimize for model learning (load parameters and learning rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training process\n",
    "def train(epoch):\n",
    "    model.train() # Put model in training mode\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # Zero out all gradients for each batch before back prop\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate loss, backward propogate, and optimize\n",
    "        loss = loss_fn(output, target) # Calculate error from desired error\n",
    "        loss.backward() # Do backward propogation for improvement\n",
    "        optimizer.step()  # Do optimizer step\n",
    "\n",
    "        if batch_idx % 25 == 0:# Every 25\n",
    "            # Fancy print statement\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)} / {len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval() # put model into eval mode\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient function and no back prop for test\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0 / 60000 (0%)]\t1.532439\n",
      "Train Epoch: 1 [2500 / 60000 (4%)]\t1.494080\n",
      "Train Epoch: 1 [5000 / 60000 (8%)]\t1.569995\n",
      "Train Epoch: 1 [7500 / 60000 (12%)]\t1.474046\n",
      "Train Epoch: 1 [10000 / 60000 (17%)]\t1.529496\n",
      "Train Epoch: 1 [12500 / 60000 (21%)]\t1.536009\n",
      "Train Epoch: 1 [15000 / 60000 (25%)]\t1.550536\n",
      "Train Epoch: 1 [17500 / 60000 (29%)]\t1.517910\n",
      "Train Epoch: 1 [20000 / 60000 (33%)]\t1.517979\n",
      "Train Epoch: 1 [22500 / 60000 (38%)]\t1.491891\n",
      "Train Epoch: 1 [25000 / 60000 (42%)]\t1.522354\n",
      "Train Epoch: 1 [27500 / 60000 (46%)]\t1.506607\n",
      "Train Epoch: 1 [30000 / 60000 (50%)]\t1.590727\n",
      "Train Epoch: 1 [32500 / 60000 (54%)]\t1.523128\n",
      "Train Epoch: 1 [35000 / 60000 (58%)]\t1.534483\n",
      "Train Epoch: 1 [37500 / 60000 (62%)]\t1.497007\n",
      "Train Epoch: 1 [40000 / 60000 (67%)]\t1.531430\n",
      "Train Epoch: 1 [42500 / 60000 (71%)]\t1.562594\n",
      "Train Epoch: 1 [45000 / 60000 (75%)]\t1.503861\n",
      "Train Epoch: 1 [47500 / 60000 (79%)]\t1.504333\n",
      "Train Epoch: 1 [50000 / 60000 (83%)]\t1.515047\n",
      "Train Epoch: 1 [52500 / 60000 (88%)]\t1.512007\n",
      "Train Epoch: 1 [55000 / 60000 (92%)]\t1.498710\n",
      "Train Epoch: 1 [57500 / 60000 (96%)]\t1.496904\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9761/10000 (98%\n",
      ")\n",
      "Train Epoch: 2 [0 / 60000 (0%)]\t1.569560\n",
      "Train Epoch: 2 [2500 / 60000 (4%)]\t1.551873\n",
      "Train Epoch: 2 [5000 / 60000 (8%)]\t1.481027\n",
      "Train Epoch: 2 [7500 / 60000 (12%)]\t1.546782\n",
      "Train Epoch: 2 [10000 / 60000 (17%)]\t1.512841\n",
      "Train Epoch: 2 [12500 / 60000 (21%)]\t1.512612\n",
      "Train Epoch: 2 [15000 / 60000 (25%)]\t1.523618\n",
      "Train Epoch: 2 [17500 / 60000 (29%)]\t1.525845\n",
      "Train Epoch: 2 [20000 / 60000 (33%)]\t1.496288\n",
      "Train Epoch: 2 [22500 / 60000 (38%)]\t1.487875\n",
      "Train Epoch: 2 [25000 / 60000 (42%)]\t1.539154\n",
      "Train Epoch: 2 [27500 / 60000 (46%)]\t1.504215\n",
      "Train Epoch: 2 [30000 / 60000 (50%)]\t1.565438\n",
      "Train Epoch: 2 [32500 / 60000 (54%)]\t1.538432\n",
      "Train Epoch: 2 [35000 / 60000 (58%)]\t1.510668\n",
      "Train Epoch: 2 [37500 / 60000 (62%)]\t1.507846\n",
      "Train Epoch: 2 [40000 / 60000 (67%)]\t1.571756\n",
      "Train Epoch: 2 [42500 / 60000 (71%)]\t1.534171\n",
      "Train Epoch: 2 [45000 / 60000 (75%)]\t1.502108\n",
      "Train Epoch: 2 [47500 / 60000 (79%)]\t1.523572\n",
      "Train Epoch: 2 [50000 / 60000 (83%)]\t1.522191\n",
      "Train Epoch: 2 [52500 / 60000 (88%)]\t1.512869\n",
      "Train Epoch: 2 [55000 / 60000 (92%)]\t1.490998\n",
      "Train Epoch: 2 [57500 / 60000 (96%)]\t1.520281\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9761/10000 (98%\n",
      ")\n",
      "Train Epoch: 3 [0 / 60000 (0%)]\t1.500806\n",
      "Train Epoch: 3 [2500 / 60000 (4%)]\t1.516896\n",
      "Train Epoch: 3 [5000 / 60000 (8%)]\t1.507773\n",
      "Train Epoch: 3 [7500 / 60000 (12%)]\t1.518993\n",
      "Train Epoch: 3 [10000 / 60000 (17%)]\t1.529538\n",
      "Train Epoch: 3 [12500 / 60000 (21%)]\t1.519200\n",
      "Train Epoch: 3 [15000 / 60000 (25%)]\t1.498555\n",
      "Train Epoch: 3 [17500 / 60000 (29%)]\t1.512167\n",
      "Train Epoch: 3 [20000 / 60000 (33%)]\t1.525481\n",
      "Train Epoch: 3 [22500 / 60000 (38%)]\t1.539452\n",
      "Train Epoch: 3 [25000 / 60000 (42%)]\t1.540854\n",
      "Train Epoch: 3 [27500 / 60000 (46%)]\t1.528008\n",
      "Train Epoch: 3 [30000 / 60000 (50%)]\t1.507171\n",
      "Train Epoch: 3 [32500 / 60000 (54%)]\t1.512453\n",
      "Train Epoch: 3 [35000 / 60000 (58%)]\t1.505829\n",
      "Train Epoch: 3 [37500 / 60000 (62%)]\t1.524756\n",
      "Train Epoch: 3 [40000 / 60000 (67%)]\t1.512160\n",
      "Train Epoch: 3 [42500 / 60000 (71%)]\t1.512030\n",
      "Train Epoch: 3 [45000 / 60000 (75%)]\t1.534999\n",
      "Train Epoch: 3 [47500 / 60000 (79%)]\t1.532230\n",
      "Train Epoch: 3 [50000 / 60000 (83%)]\t1.552068\n",
      "Train Epoch: 3 [52500 / 60000 (88%)]\t1.521007\n",
      "Train Epoch: 3 [55000 / 60000 (92%)]\t1.539244\n",
      "Train Epoch: 3 [57500 / 60000 (96%)]\t1.580359\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9773/10000 (98%\n",
      ")\n",
      "Train Epoch: 4 [0 / 60000 (0%)]\t1.480446\n",
      "Train Epoch: 4 [2500 / 60000 (4%)]\t1.517533\n",
      "Train Epoch: 4 [5000 / 60000 (8%)]\t1.519888\n",
      "Train Epoch: 4 [7500 / 60000 (12%)]\t1.497639\n",
      "Train Epoch: 4 [10000 / 60000 (17%)]\t1.488967\n",
      "Train Epoch: 4 [12500 / 60000 (21%)]\t1.514167\n",
      "Train Epoch: 4 [15000 / 60000 (25%)]\t1.489995\n",
      "Train Epoch: 4 [17500 / 60000 (29%)]\t1.558360\n",
      "Train Epoch: 4 [20000 / 60000 (33%)]\t1.537857\n",
      "Train Epoch: 4 [22500 / 60000 (38%)]\t1.575978\n",
      "Train Epoch: 4 [25000 / 60000 (42%)]\t1.534748\n",
      "Train Epoch: 4 [27500 / 60000 (46%)]\t1.526739\n",
      "Train Epoch: 4 [30000 / 60000 (50%)]\t1.516443\n",
      "Train Epoch: 4 [32500 / 60000 (54%)]\t1.497319\n",
      "Train Epoch: 4 [35000 / 60000 (58%)]\t1.543047\n",
      "Train Epoch: 4 [37500 / 60000 (62%)]\t1.529033\n",
      "Train Epoch: 4 [40000 / 60000 (67%)]\t1.527718\n",
      "Train Epoch: 4 [42500 / 60000 (71%)]\t1.539450\n",
      "Train Epoch: 4 [45000 / 60000 (75%)]\t1.536523\n",
      "Train Epoch: 4 [47500 / 60000 (79%)]\t1.475783\n",
      "Train Epoch: 4 [50000 / 60000 (83%)]\t1.521511\n",
      "Train Epoch: 4 [52500 / 60000 (88%)]\t1.479488\n",
      "Train Epoch: 4 [55000 / 60000 (92%)]\t1.567266\n",
      "Train Epoch: 4 [57500 / 60000 (96%)]\t1.479941\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9770/10000 (98%\n",
      ")\n",
      "Train Epoch: 5 [0 / 60000 (0%)]\t1.498721\n",
      "Train Epoch: 5 [2500 / 60000 (4%)]\t1.541681\n",
      "Train Epoch: 5 [5000 / 60000 (8%)]\t1.534216\n",
      "Train Epoch: 5 [7500 / 60000 (12%)]\t1.538733\n",
      "Train Epoch: 5 [10000 / 60000 (17%)]\t1.492917\n",
      "Train Epoch: 5 [12500 / 60000 (21%)]\t1.474697\n",
      "Train Epoch: 5 [15000 / 60000 (25%)]\t1.544225\n",
      "Train Epoch: 5 [17500 / 60000 (29%)]\t1.484354\n",
      "Train Epoch: 5 [20000 / 60000 (33%)]\t1.563831\n",
      "Train Epoch: 5 [22500 / 60000 (38%)]\t1.521211\n",
      "Train Epoch: 5 [25000 / 60000 (42%)]\t1.494361\n",
      "Train Epoch: 5 [27500 / 60000 (46%)]\t1.529416\n",
      "Train Epoch: 5 [30000 / 60000 (50%)]\t1.520999\n",
      "Train Epoch: 5 [32500 / 60000 (54%)]\t1.560441\n",
      "Train Epoch: 5 [35000 / 60000 (58%)]\t1.512800\n",
      "Train Epoch: 5 [37500 / 60000 (62%)]\t1.532809\n",
      "Train Epoch: 5 [40000 / 60000 (67%)]\t1.481310\n",
      "Train Epoch: 5 [42500 / 60000 (71%)]\t1.483265\n",
      "Train Epoch: 5 [45000 / 60000 (75%)]\t1.548021\n",
      "Train Epoch: 5 [47500 / 60000 (79%)]\t1.539045\n",
      "Train Epoch: 5 [50000 / 60000 (83%)]\t1.502957\n",
      "Train Epoch: 5 [52500 / 60000 (88%)]\t1.546563\n",
      "Train Epoch: 5 [55000 / 60000 (92%)]\t1.506277\n",
      "Train Epoch: 5 [57500 / 60000 (96%)]\t1.493451\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9784/10000 (98%\n",
      ")\n",
      "Train Epoch: 6 [0 / 60000 (0%)]\t1.513213\n",
      "Train Epoch: 6 [2500 / 60000 (4%)]\t1.489302\n",
      "Train Epoch: 6 [5000 / 60000 (8%)]\t1.510811\n",
      "Train Epoch: 6 [7500 / 60000 (12%)]\t1.500467\n",
      "Train Epoch: 6 [10000 / 60000 (17%)]\t1.524421\n",
      "Train Epoch: 6 [12500 / 60000 (21%)]\t1.516586\n",
      "Train Epoch: 6 [15000 / 60000 (25%)]\t1.511345\n",
      "Train Epoch: 6 [17500 / 60000 (29%)]\t1.472623\n",
      "Train Epoch: 6 [20000 / 60000 (33%)]\t1.485873\n",
      "Train Epoch: 6 [22500 / 60000 (38%)]\t1.527550\n",
      "Train Epoch: 6 [25000 / 60000 (42%)]\t1.520103\n",
      "Train Epoch: 6 [27500 / 60000 (46%)]\t1.524464\n",
      "Train Epoch: 6 [30000 / 60000 (50%)]\t1.523903\n",
      "Train Epoch: 6 [32500 / 60000 (54%)]\t1.516140\n",
      "Train Epoch: 6 [35000 / 60000 (58%)]\t1.510665\n",
      "Train Epoch: 6 [37500 / 60000 (62%)]\t1.484982\n",
      "Train Epoch: 6 [40000 / 60000 (67%)]\t1.512425\n",
      "Train Epoch: 6 [42500 / 60000 (71%)]\t1.516448\n",
      "Train Epoch: 6 [45000 / 60000 (75%)]\t1.492641\n",
      "Train Epoch: 6 [47500 / 60000 (79%)]\t1.521121\n",
      "Train Epoch: 6 [50000 / 60000 (83%)]\t1.523491\n",
      "Train Epoch: 6 [52500 / 60000 (88%)]\t1.502035\n",
      "Train Epoch: 6 [55000 / 60000 (92%)]\t1.500141\n",
      "Train Epoch: 6 [57500 / 60000 (96%)]\t1.519331\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9797/10000 (98%\n",
      ")\n",
      "Train Epoch: 7 [0 / 60000 (0%)]\t1.517767\n",
      "Train Epoch: 7 [2500 / 60000 (4%)]\t1.534702\n",
      "Train Epoch: 7 [5000 / 60000 (8%)]\t1.511886\n",
      "Train Epoch: 7 [7500 / 60000 (12%)]\t1.495466\n",
      "Train Epoch: 7 [10000 / 60000 (17%)]\t1.520647\n",
      "Train Epoch: 7 [12500 / 60000 (21%)]\t1.536065\n",
      "Train Epoch: 7 [15000 / 60000 (25%)]\t1.514250\n",
      "Train Epoch: 7 [17500 / 60000 (29%)]\t1.529505\n",
      "Train Epoch: 7 [20000 / 60000 (33%)]\t1.476254\n",
      "Train Epoch: 7 [22500 / 60000 (38%)]\t1.538900\n",
      "Train Epoch: 7 [25000 / 60000 (42%)]\t1.520220\n",
      "Train Epoch: 7 [27500 / 60000 (46%)]\t1.492690\n",
      "Train Epoch: 7 [30000 / 60000 (50%)]\t1.505358\n",
      "Train Epoch: 7 [32500 / 60000 (54%)]\t1.547581\n",
      "Train Epoch: 7 [35000 / 60000 (58%)]\t1.532117\n",
      "Train Epoch: 7 [37500 / 60000 (62%)]\t1.510626\n",
      "Train Epoch: 7 [40000 / 60000 (67%)]\t1.537530\n",
      "Train Epoch: 7 [42500 / 60000 (71%)]\t1.515586\n",
      "Train Epoch: 7 [45000 / 60000 (75%)]\t1.533856\n",
      "Train Epoch: 7 [47500 / 60000 (79%)]\t1.506858\n",
      "Train Epoch: 7 [50000 / 60000 (83%)]\t1.527489\n",
      "Train Epoch: 7 [52500 / 60000 (88%)]\t1.528722\n",
      "Train Epoch: 7 [55000 / 60000 (92%)]\t1.488432\n",
      "Train Epoch: 7 [57500 / 60000 (96%)]\t1.525287\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9801/10000 (98%\n",
      ")\n",
      "Train Epoch: 8 [0 / 60000 (0%)]\t1.476771\n",
      "Train Epoch: 8 [2500 / 60000 (4%)]\t1.509009\n",
      "Train Epoch: 8 [5000 / 60000 (8%)]\t1.495589\n",
      "Train Epoch: 8 [7500 / 60000 (12%)]\t1.499272\n",
      "Train Epoch: 8 [10000 / 60000 (17%)]\t1.520805\n",
      "Train Epoch: 8 [12500 / 60000 (21%)]\t1.501411\n",
      "Train Epoch: 8 [15000 / 60000 (25%)]\t1.533998\n",
      "Train Epoch: 8 [17500 / 60000 (29%)]\t1.518848\n",
      "Train Epoch: 8 [20000 / 60000 (33%)]\t1.529134\n",
      "Train Epoch: 8 [22500 / 60000 (38%)]\t1.509271\n",
      "Train Epoch: 8 [25000 / 60000 (42%)]\t1.506527\n",
      "Train Epoch: 8 [27500 / 60000 (46%)]\t1.517434\n",
      "Train Epoch: 8 [30000 / 60000 (50%)]\t1.560288\n",
      "Train Epoch: 8 [32500 / 60000 (54%)]\t1.518690\n",
      "Train Epoch: 8 [35000 / 60000 (58%)]\t1.553676\n",
      "Train Epoch: 8 [37500 / 60000 (62%)]\t1.505013\n",
      "Train Epoch: 8 [40000 / 60000 (67%)]\t1.485178\n",
      "Train Epoch: 8 [42500 / 60000 (71%)]\t1.511525\n",
      "Train Epoch: 8 [45000 / 60000 (75%)]\t1.527848\n",
      "Train Epoch: 8 [47500 / 60000 (79%)]\t1.488141\n",
      "Train Epoch: 8 [50000 / 60000 (83%)]\t1.502970\n",
      "Train Epoch: 8 [52500 / 60000 (88%)]\t1.518597\n",
      "Train Epoch: 8 [55000 / 60000 (92%)]\t1.517290\n",
      "Train Epoch: 8 [57500 / 60000 (96%)]\t1.488784\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9795/10000 (98%\n",
      ")\n",
      "Train Epoch: 9 [0 / 60000 (0%)]\t1.514700\n",
      "Train Epoch: 9 [2500 / 60000 (4%)]\t1.510005\n",
      "Train Epoch: 9 [5000 / 60000 (8%)]\t1.488724\n",
      "Train Epoch: 9 [7500 / 60000 (12%)]\t1.503033\n",
      "Train Epoch: 9 [10000 / 60000 (17%)]\t1.496139\n",
      "Train Epoch: 9 [12500 / 60000 (21%)]\t1.533468\n",
      "Train Epoch: 9 [15000 / 60000 (25%)]\t1.502596\n",
      "Train Epoch: 9 [17500 / 60000 (29%)]\t1.558549\n",
      "Train Epoch: 9 [20000 / 60000 (33%)]\t1.500323\n",
      "Train Epoch: 9 [22500 / 60000 (38%)]\t1.518463\n",
      "Train Epoch: 9 [25000 / 60000 (42%)]\t1.514471\n",
      "Train Epoch: 9 [27500 / 60000 (46%)]\t1.485299\n",
      "Train Epoch: 9 [30000 / 60000 (50%)]\t1.519910\n",
      "Train Epoch: 9 [32500 / 60000 (54%)]\t1.523739\n",
      "Train Epoch: 9 [35000 / 60000 (58%)]\t1.519612\n",
      "Train Epoch: 9 [37500 / 60000 (62%)]\t1.514419\n",
      "Train Epoch: 9 [40000 / 60000 (67%)]\t1.501117\n",
      "Train Epoch: 9 [42500 / 60000 (71%)]\t1.489498\n",
      "Train Epoch: 9 [45000 / 60000 (75%)]\t1.521855\n",
      "Train Epoch: 9 [47500 / 60000 (79%)]\t1.512590\n",
      "Train Epoch: 9 [50000 / 60000 (83%)]\t1.534916\n",
      "Train Epoch: 9 [52500 / 60000 (88%)]\t1.485774\n",
      "Train Epoch: 9 [55000 / 60000 (92%)]\t1.531443\n",
      "Train Epoch: 9 [57500 / 60000 (96%)]\t1.515762\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9819/10000 (98%\n",
      ")\n",
      "Train Epoch: 10 [0 / 60000 (0%)]\t1.514105\n",
      "Train Epoch: 10 [2500 / 60000 (4%)]\t1.500880\n",
      "Train Epoch: 10 [5000 / 60000 (8%)]\t1.506651\n",
      "Train Epoch: 10 [7500 / 60000 (12%)]\t1.509052\n",
      "Train Epoch: 10 [10000 / 60000 (17%)]\t1.512816\n",
      "Train Epoch: 10 [12500 / 60000 (21%)]\t1.495672\n",
      "Train Epoch: 10 [15000 / 60000 (25%)]\t1.538844\n",
      "Train Epoch: 10 [17500 / 60000 (29%)]\t1.528545\n",
      "Train Epoch: 10 [20000 / 60000 (33%)]\t1.506082\n",
      "Train Epoch: 10 [22500 / 60000 (38%)]\t1.498765\n",
      "Train Epoch: 10 [25000 / 60000 (42%)]\t1.532373\n",
      "Train Epoch: 10 [27500 / 60000 (46%)]\t1.481169\n",
      "Train Epoch: 10 [30000 / 60000 (50%)]\t1.552323\n",
      "Train Epoch: 10 [32500 / 60000 (54%)]\t1.492581\n",
      "Train Epoch: 10 [35000 / 60000 (58%)]\t1.509475\n",
      "Train Epoch: 10 [37500 / 60000 (62%)]\t1.506745\n",
      "Train Epoch: 10 [40000 / 60000 (67%)]\t1.533320\n",
      "Train Epoch: 10 [42500 / 60000 (71%)]\t1.512709\n",
      "Train Epoch: 10 [45000 / 60000 (75%)]\t1.531601\n",
      "Train Epoch: 10 [47500 / 60000 (79%)]\t1.482465\n",
      "Train Epoch: 10 [50000 / 60000 (83%)]\t1.548785\n",
      "Train Epoch: 10 [52500 / 60000 (88%)]\t1.470111\n",
      "Train Epoch: 10 [55000 / 60000 (92%)]\t1.544702\n",
      "Train Epoch: 10 [57500 / 60000 (96%)]\t1.524254\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9804/10000 (98%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':   \n",
    "    for epoch in range(1,11):\n",
    "        train(epoch)\n",
    "        test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
